"""
Algoritmo di linear regression.
Vengono dati in input i campi "Tipo_Mat" , "Voto_Diploma" e cfu_primo (letti dal file ListStudent.txt)
e si cerca di estrapolare un'equazione in grado di predirre se lo studente andr√† o meno fuori corso.


I risultati sono pessimi poich√®:
1. La quantit√† di dati a disposizione √® minima
2. Gli attributi predittivi presi in esame sono altamente scorrelati fra di loro




Il coefficiente di determinazione , indicato come ùëÖ¬≤, indica quale quantit√† di variazione in ùë¶ pu√≤ essere spiegata
 dalla dipendenza da ùê± usando il particolare modello di regressione.
 Pi√π grande ùëÖ¬≤ indica un adattamento migliore e significa che il modello pu√≤ spiegare meglio la variazione dell'output con input diversi.

Il valore ùëÖ¬≤ = 1 corrisponde a SSR = 0, ovvero alla misura perfetta poich√© i valori delle risposte previste ed effettive
 si adattano completamente l'uno all'altro.
"""

import numpy as np
from sklearn.linear_model import LinearRegression
import json
from matplotlib import pyplot as plt
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
import pandas as pd


Predictive_Value = []
predictiveTemp = []
Result = []
Maturit√† = json.load(open("C:/Users/clara/PycharmProjects/prog2/DSML_Task2/FileGenerated/ListStudent.txt")) #ATTENZIONE AL PATH

#Dict=json.load(open("C:/Users/clara/PycharmProjects/prog2/DSML_Task2/FileGenerated/DictSchool.txt"))

#print(Dict)
#divido io dataset 80 train e 20 test
Train_size = int((len(Maturit√†) / 100) * 80)
Test_size = int((len(Maturit√†)/100) * 20)
Train_set = []
Test_set = []
Result_Test = []
Total_Set = []
Tota_Result = []
# Total_Write = []
# Total_Temp = []
count =0
for i in range(0, len(Maturit√†)):
    tipo_maturit√† = int(Maturit√†[i][0][0])#primo volore predittivo
    voto_diploma = int(Maturit√†[i][0][1])#secondo valore predittivo
    cfu_primo = int(Maturit√†[i][0][2])#terzo valore predittivo
    count=count+1
    TrainTemp = [tipo_maturit√†, voto_diploma, cfu_primo]
    Total_Temp = [tipo_maturit√†, voto_diploma,cfu_primo, int(Maturit√†[i][0][3])]
    Tota_Result.append(int(Maturit√†[i][0][3]))
    Result.append(int(Maturit√†[i][0][3]))
    Total_Set.append(TrainTemp)
    Train_set.append(TrainTemp)
    #Total_Write.append(Total_Temp)

print(count)
# df = pd.DataFrame(data={"Tipo_Maturita, Voto_Diploma, CFU_Primo": Total_Write})
# df.to_csv("./TotalStudent.csv", sep=',', index=False,)
Train_set, Test_set, Result,  Result_Test= train_test_split(Train_set, Result, test_size=0.3)
Train_set, Result = np.array(Train_set), np.array(Result)
Train_set, Result = np.array(Train_set), np.array(Result)

"""   
Quando si implementa la regressione lineare di una variabile dipendente ùë¶ sull'insieme di variabili indipendenti 
ùê± = (ùë•‚ÇÅ,‚Ä¶, ùë•·µ£), dove ùëü √® il numero di predittori, si assume una relazione lineare tra ùë¶ e ùê±: ùë¶ = ùõΩ‚ÇÄ + ùõΩ‚ÇÅùë•‚ÇÅ + ‚ãØ + ùõΩ·µ£ùë•·µ£ + ùúÄ.
 Questa equazione √® l' equazione di regressione . 
 ùõΩ‚ÇÄ, ùõΩ‚ÇÅ,‚Ä¶, ùõΩ·µ£ sono i coefficienti di regressione e ùúÄ √® l' errore casuale .
 
 La regressione lineare calcola gli stimatori dei coefficienti di regressione o semplicemente i pesi previsti , indicati con ùëè‚ÇÄ, ùëè‚ÇÅ, ..., ùëè·µ£. 
 Definiscono la funzione di regressione stimata ùëì (ùê±) = ùëè‚ÇÄ + ùëè‚ÇÅùë•‚ÇÅ + ‚ãØ + ùëè·µ£ùë•·µ£. 
 Questa funzione dovrebbe catturare sufficientemente bene le dipendenze tra input e output.
 
 
 La risposta stimata o prevista , ùëì (ùê±·µ¢), per ogni osservazione ùëñ = 1,‚Ä¶, ùëõ, deve essere il pi√π vicino possibile alla risposta effettiva corrispondente ùë¶·µ¢.
  Le differenze ùë¶·µ¢ - ùëì (ùê±·µ¢) per tutte le osservazioni ùëñ = 1,‚Ä¶, ùëõ, sono chiamate residui . 
  La regressione riguarda la determinazione dei pesi migliori previsti , ovvero i pesi corrispondenti ai residui pi√π piccoli.
  
  Per ottenere i pesi migliori, di solito si minimizza la somma dei residui quadrati (SSR) per tutte le osservazioni ùëñ = 1,‚Ä¶, ùëõ: SSR = Œ£·µ¢ (ùë¶·µ¢ - ùëì (ùê±·µ¢)) ¬≤. 
  Questo approccio √® chiamato il metodo dei minimi quadrati ordinari .
  
  Il coefficiente di determinazione , indicato come ùëÖ¬≤, indica quale quantit√† di variazione in ùë¶ pu√≤ essere spiegata dalla dipendenza da ùê± 
  usando il particolare modello di regressione. Pi√π grande ùëÖ¬≤ indica un adattamento migliore e significa che il modello pu√≤ spiegare meglio la 
  variazione dell'output con input diversi.

Il valore ùëÖ¬≤ = 1 corrisponde a SSR = 0, ovvero alla misura perfetta poich√© i valori delle risposte previste ed 
effettive si adattano completamente l'uno all'altro.
 Il tuo obiettivo √® calcolare i valori ottimali dei pesi previsti ùëè‚ÇÄ e ùëè‚ÇÅ che minimizzano l'SSR e determinano la funzione di regressione stimata. Il valore di ùëè‚ÇÄ, 
 chiamato anche intercetta , mostra il punto in cui la linea di regressione stimata attraversa l'asse ùë¶. 
"""
model = LinearRegression()
model.fit(Train_set, Result)
r_sq = model.score(Train_set, Result)
print("Coefficient of determination: ", r_sq)
print("intercept: ", model.intercept_)
print("slope: ", model.coef_)
maximum = 0.0
sw = 0
minus = 0.0
y_pred_pred = []
for item in Test_set:
    tipo_maturit√† = item[0]
    voto_diploma = int(item[1])
    cfu_primo =int(item[2])
    predictiveTemp = [[tipo_maturit√†, voto_diploma, cfu_primo]]
    predictiveTemp = np.array(predictiveTemp)
    y_pred = model.predict(predictiveTemp)
    y_pred = float(y_pred)
    y_pred_pred.append(y_pred)
    if y_pred > 0:
        if sw == 0:
            minus = y_pred
            min_school = tipo_maturit√†
            sw = 1
        elif minus > y_pred:
            minus = y_pred
            min_school = tipo_maturit√†
        if y_pred > maximum:
            maximum = y_pred
            max_school = tipo_maturit√†

print("Highest score: ", maximum, "of type ",tipo_maturit√†, sep="\n")
print("Worst score: ", minus, "of school ", tipo_maturit√†, sep="\n")


def plot_learning_curves(model, X, y):
    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)
    train_errors, val_errors = [], []
    for m in range(1, len(X_train)):
        model.fit(X_train[:m], y_train[:m])
        y_train_predict = model.predict(X_train[:m])
        y_val_predict = model.predict(X_val)
        train_errors.append(mean_squared_error(y_train_predict, y_train[:m]))
        val_errors.append(mean_squared_error(y_val_predict, y_val))
    plt.plot(np.sqrt(train_errors), "r-+", linewidth=2, label="train")
    plt.plot(np.sqrt(val_errors), "b-", linewidth=3, label="val")
    plt.show()


plot_learning_curves(model, Total_Set, Tota_Result)
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error

print("R2Score : ", r2_score(Result_Test, y_pred_pred))
print("MSE : ", mean_squared_error(Result_Test, y_pred_pred))